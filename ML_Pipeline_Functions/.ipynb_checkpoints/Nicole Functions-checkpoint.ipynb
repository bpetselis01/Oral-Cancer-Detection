{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2e62e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36a4f4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the MATLAB data into appropriate dictionary with patient labels\n",
    "# We need to use this function multiple times to create cancer_data_dict and benign_data_dict\n",
    "def convert_data_to_dict(mat_file_path, data_labels, mat_file_name, mat_file_parameter):\n",
    "    data_dict = {}\n",
    "\n",
    "    for label in data_labels:\n",
    "        file_path = os.path.join(mat_file_path, f\"{label}{mat_file_name}.mat\")\n",
    "        mat_file = loadmat(file_path)\n",
    "        feature = mat_file[mat_file_parameter]\n",
    "\n",
    "        # Extract xsize, ysize, and zsize\n",
    "        xsize, ysize, zsize = feature.shape\n",
    "        data_dict[label] = feature.reshape((xsize * ysize, zsize))\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "# Example usage:\n",
    "# mat_file_path = \"/Users/Nicol/OneDrive/Desktop/Nicole_UNSW/VIP 2023/Features - Qatar/\"\n",
    "# mat_file_name = \"_LESION_full_feature\"\n",
    "# data_labels = [\"Q3\", \"Q8\", \"Q12\", \"Q15\", \"Q17\", \"Q22\", \"Q24\", \"Q26\", \"Q28\", \"Q29\", \"Q30\", \"Q31\", \"Q32\", \"Q33\", \"Q36\", \"Q39\", \"Q41\", \"Q44\", \"Q45\", \"Q47\", \"Q48\", \"Q51\", \"Q53\", \"Q55\", \"Q57\", \"Q58\", \"Q61\", \"Q64\", \"Q68\"]\n",
    "# mat_file_parameter = \"full_feature\"\n",
    "\n",
    "# cancer_data_dict = convert_data_to_dict(mat_file_path, data_labels, mat_file_name, mat_file_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d52a9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the MATLAB mask into appropriate dictionary with patient labels\n",
    "def convert_mask_to_dict(mat_file_path, mask_labels, mat_file_name, mat_file_parameter):\n",
    "    mask_dict = {}\n",
    "\n",
    "    for label in mask_labels:\n",
    "        file_path = os.path.join(mat_file_path, f\"{label}{mat_file_name}.mat\")\n",
    "        mat_file = loadmat(file_path)\n",
    "        mask = mat_file[mat_file_parameter]\n",
    "\n",
    "        # Assuming mask is a 1D array with appropriate data\n",
    "        mask_dict[label] = mask.flatten()\n",
    "\n",
    "    return mask_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea525d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data_dict):\n",
    "    min_val = np.inf\n",
    "    max_val = -np.inf\n",
    "    \n",
    "    # Find the global minimum and maximum values across all arrays\n",
    "    for key, value in data_dict.items():\n",
    "        local_min = np.min(value, axis=0)\n",
    "        local_max = np.max(value, axis=0)\n",
    "        min_val = np.minimum(local_min, min_val)\n",
    "        max_val = np.maximum(local_max, max_val)\n",
    "    \n",
    "    normalized_dict = {}\n",
    "    \n",
    "    # Normalize each array using the global minimum and maximum values\n",
    "    for key, value in data_dict.items():\n",
    "        normalized = (value - min_val) / (max_val - min_val)\n",
    "        normalized_dict[key] = normalized\n",
    "    \n",
    "    return normalized_dict\n",
    "\n",
    "# Example usage:\n",
    "# cancer_data_dict = normalize(cancer_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b0d7fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize_labels(labels):\n",
    "    return np.random.permutation(labels)\n",
    "\n",
    "# Example usage:\n",
    "# randomized_labels = randomize_labels(data_labels)\n",
    "# print(randomized_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c2b3e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split labels into groups based on a percentage\n",
    "# Example: [1,2,3,4,5,6,7,8,9,10] and 0.3 percent will give [[1,2,3],[4,5,6],[7,8,9,10]]\n",
    "def split_labels(labels, percentage):\n",
    "    num_elements = math.floor(percentage * len(labels))\n",
    "    num_rows = math.floor(len(labels) / num_elements)\n",
    "\n",
    "    # Create a dictionary to store sets of labels\n",
    "    divided_labels = {}\n",
    "    \n",
    "    for i in range(1, num_rows + 1):\n",
    "        start_index = (i - 1) * num_elements\n",
    "        end_index = min(i * num_elements, len(labels))\n",
    "        set_of_labels = labels[start_index:end_index]\n",
    "\n",
    "        # Store the set in the dictionary with the row index as the key\n",
    "        divided_labels[i] = set_of_labels\n",
    "\n",
    "    # Handle the leftover labels\n",
    "    leftover_index = num_elements * num_rows\n",
    "    divided_labels[num_rows + 1] = labels[leftover_index:]\n",
    "\n",
    "    return divided_labels\n",
    "\n",
    "# Example usage:\n",
    "# splitted_labels = split_labels(randomized_labels, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "267269b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to select one group of labels from splitLabels (which will be set aside and used for testing)\n",
    "def select_labels(split_labels):\n",
    "    # Assuming you want to select the first group\n",
    "    first_entry = list(split_labels.items())[0]\n",
    "    first_value = first_entry[1]\n",
    "    return first_value\n",
    "\n",
    "# Example usage:\n",
    "# selected_labels = select_labels(splitted_labels)\n",
    "# print(selected_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b93a052f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get testing data based on selected labels\n",
    "# testing data will be popped off data_dict\n",
    "def get_testing_data(data_dict, selected_labels, transpose):\n",
    "    testing_data = []\n",
    "    \n",
    "    for key in selected_labels:\n",
    "        data = data_dict.pop(key)\n",
    "        testing_data.append(data.T if transpose else data)\n",
    "    \n",
    "    return testing_data, data_dict\n",
    "\n",
    "# Example usage:\n",
    "# testing_data, cancer_data_dict = get_testing_data(cancer_data_dict, selected_labels, False)\n",
    "# for data in testing_data:\n",
    "#     print(f\"Size of testing data: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e48fd133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get training data from the remaining data in data_dict\n",
    "def get_training_data(data_dict, transpose):\n",
    "    training_data = []\n",
    "    \n",
    "    # Create a copy of the keys to avoid dictionary size changes during iteration\n",
    "    keys_to_remove = list(data_dict.keys())\n",
    "    \n",
    "    for key in keys_to_remove:\n",
    "        data = data_dict.pop(key)\n",
    "        training_data.append(data.T if transpose else data)\n",
    "    \n",
    "    return training_data\n",
    "\n",
    "# Example usage:\n",
    "# training_data = get_training_data(cancer_data_dict, False)\n",
    "# for data in training_data:\n",
    "#     print(f\"Size of training data: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91e7081b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of testing data: (25600, 15)\n",
      "Size of testing data: (25600, 15)\n",
      "Size of testing data: (25600, 15)\n",
      "Size of testing data: (25600, 15)\n",
      "Size of testing data: (25600, 15)\n",
      "Size of training data: (25600, 15)\n",
      "Size of training data: (25600, 15)\n",
      "Size of training data: (25600, 15)\n",
      "Size of training data: (25600, 15)\n",
      "Size of training data: (25600, 15)\n",
      "Size of training data: (25600, 15)\n",
      "Size of training data: (25600, 15)\n",
      "Size of training data: (25600, 15)\n",
      "Size of training data: (25600, 15)\n",
      "Size of training data: (25600, 15)\n",
      "Size of training data: (25600, 15)\n",
      "Size of training data: (25600, 15)\n",
      "Size of training data: (25600, 15)\n",
      "Size of training data: (25600, 15)\n",
      "Size of training data: (25600, 15)\n",
      "Size of training data: (25600, 15)\n",
      "Size of training data: (25600, 15)\n",
      "Size of training data: (25600, 15)\n",
      "Size of training data: (25600, 15)\n",
      "Size of training data: (25600, 15)\n",
      "Size of training data: (25600, 15)\n",
      "Size of training data: (25600, 15)\n",
      "Size of training data: (25600, 15)\n",
      "Size of training data: (25600, 15)\n"
     ]
    }
   ],
   "source": [
    "# Example usage for cancer data\n",
    "mat_file_path = \"/Users/Nicol/OneDrive/Desktop/Nicole_UNSW/VIP 2023/Features - Qatar/\"\n",
    "mat_file_name = \"_LESION_full_feature\"\n",
    "data_labels = [\"Q3\", \"Q8\", \"Q12\", \"Q15\", \"Q17\", \"Q22\", \"Q24\", \"Q26\", \"Q28\", \"Q29\", \"Q30\", \"Q31\", \"Q32\", \"Q33\", \"Q36\", \"Q39\", \"Q41\", \"Q44\", \"Q45\", \"Q47\", \"Q48\", \"Q51\", \"Q53\", \"Q55\", \"Q57\", \"Q58\", \"Q61\", \"Q64\", \"Q68\"]\n",
    "mat_file_parameter = \"full_feature\"\n",
    "\n",
    "cancer_data_dict = convert_data_to_dict(mat_file_path, data_labels, mat_file_name, mat_file_parameter)\n",
    "cancer_data_dict = normalize(cancer_data_dict)\n",
    "randomized_labels = randomize_labels(data_labels)\n",
    "splitted_labels = split_labels(randomized_labels, 0.2)\n",
    "selected_labels = select_labels(splitted_labels)\n",
    "\n",
    "testing_data, cancer_data_dict = get_testing_data(cancer_data_dict, selected_labels, False)\n",
    "for data in testing_data:\n",
    "    print(f\"Size of testing data: {data.shape}\")\n",
    "\n",
    "training_data = get_training_data(cancer_data_dict, False)\n",
    "for data in training_data:\n",
    "    print(f\"Size of training data: {data.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
